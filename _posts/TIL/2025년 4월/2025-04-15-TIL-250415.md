---
title: "[TIL] 2025. 4. 15."
date: 2025-04-15
categories:
  - TIL
tags:
  - TIL
  - 내일배움캠프
toc: true
toc_sticky: true
---
## 머신러닝 특강 - 분류

### 1. 머신러닝 분류 개요 및 전체 프로세스
#### 머신러닝이란?
컴퓨터가 명시적인 프로그래밍 없이 데이터로부터 패턴을 학습하여 의사결정을 내리거나 예측을 수행하는 기술

##### 머신러닝의 기본 원리
1. 데이터 학습
2. 패턴 인식
3. 예측/판단

##### 머신러닝의 분류
| 학습 유형                        | 정의                             | 목적                      | 주요 문제 유형             |
| ---------------------------- | ------------------------------ | ----------------------- | -------------------- |
| 지도학습(Supervised Learning)    | 입력과 출력이 한 쌍으로 제공되는 학습 방식       | 입력에서 출력을 예측하는 함수를 학습    | 분류, 회귀               |
| 비지도학습(Unsupervised Learning) | 출력 레이블 없이 입력 데이터만 제공되는 학습 방식   | 데이터의 구조와 패턴을 스스로 발견     | 군집화, 차원 축소, 연관 규칙 학습 |
| 강화학습(Reinforcement Learning) | 환경과 상호작용하며 보상을 최대화하는 행동 방식을 학습 | 시행착오를 통해 최적의 의사결정 전략 학습 | 가치 기반, 정책 기반, 모델 기반  |

#### 분류
지도학습의 한 종류, 데이터를 사전에 정의된 카테고리(클래스)로 구분하는 작업

##### 분
류의 목적
- 새로운 데이터가 어떤 범주(클래스)에 속하는지 예측
- 데이터의 특성을 기반으로 카테고리 구분 규칙 학습
##### 분류 문제의 유형
| 분류 유형                             | 정의                             |
| --------------------------------- | ------------------------------ |
| 이진 분류(Binary Classification)      | 데이터를 두 개의 클래스로 구분하는 문제         |
| 다중 분류(Multi-class Classification) | 세 개 이상의 클래스 중 하나로 데이터를 분류하는 문제 |

##### 분류 VS. 회귀
| 특성    | 분류(Classification)   | 회귀(Regression)       |
| ----- | -------------------- | -------------------- |
| 목적    | 데이터를 미리 정의된 범주로 구분   | 연속적인 값 예측            |
| 출력 형태 | 이산적인 클래스 레이블(범주형)    | 연속적인 숫자 값            |
| 예시    | 스팸 메일 분류, 질병 진단      | 주택 가격 예측, 판매량 예측     |
| 평가 지표 | 정확도, 정밀도, 재현율, F1점수  | RMSE, MAE, $R^2$     |
| 결정 경계 | 데이터를 클래스로 구분하는 경계 존재 | 데이터를 가장 잘 설명하는 함수 추정 |

#### 머신러닝 개발 프로세스
1. 문제 정의
	- 목적: 해결하고자 하는 문제를 명확히 정의
	- 주요 활동
		- 비즈니스 목표 이해
		- 성공 기준 설정
		- 문제 유형 결정(분류, 회귀, 군집화 등)
2. 데이터 수집
	- 목적: 모델 학습에 필요한 데이터 확보
	- 주요 활동
		- 관련 데이터 수집(내부 데이터, 외부 데이터)
			- 데이터의 대표성
			- 데이터의 양
			- 데이터 수집의 합법성 및 윤리적 측면
		- 데이터 품질 초기 평가
		- 데이터 저장 및 관리 체계 구축
3. 데이터 전처리 및 EDA(탐색적 데이터 분석)
	- 목적: 데이터 이해 및 모델 학습에 적합한 형태로 가공
	- 주요 활동
		- 데이터 정제
			- 결측치 처리
			- 이상치 탐지 및 처리
			- 중복 데이터 제거
		- 데이터 변환
			- 범주형 변수 인코딩(원-핫 인코딩, 레이블 인코딩)
			- 특성 스케일링(표준화, 정규화, 비선형 변환)
			- 특성 공학(새로운 특성 생성)
		- 탐색적 데이터 분석
			- 데이터 분포 시각화
			- 변수 간 상관관계 분석
			- 패턴 및 트렌드 발견
4. 모델 선택 및 학습
	- 목적: 문제 해결에 적합한 알고리즘 선택 및 모델 학습
	- 주요 활동
		- 훈련/검증/테스트 데이터셋 분할
		- 다양한 알고리즘 실험 및 비교
		- 모델 학습 및 초기 평가
	- 주요 분류 알고리즘
		- 로지스틱 회귀: 간단하고 해석 용이
		- 의사결정 트리: 비선형 관계 학습 가능, 시각화 쉬움
		- 랜덤 포레스트: 여러 개의 의사결정 트리를 결합한 앙상블 모델
		- SVM(Support Vector Machine): 높은 차원에서도 효과적인 분류
		- KNN(K-Nearest Neighbors): 단순하지만 효과적인 거리 기반 분류
		- 나이브 베이즈: 확률 기반 분류, 텍스트 분류에 유용
		- 신경망: 복잡한 패턴 학습 가능
5. 모델 평가 및 개선
	- 목적: 모델의 성능 평가 및 향상
	- 주요 활동
		- 모델 평가
			- 정확도, 정밀도, 재현율, F1점수
			- ROC 곡선 및 AUC
			- 혼동 행렬 분석
		- 모델 개선
			- 과적합 VS. 과소적합
			- 하이퍼파라미터 튜닝
			- 교차 검증
			- 앙상블 방법 적용
			- 특성 중요도 분석
			- 특성 선택 및 추가 특성 공학
6. 모델 배포 및 모니터링
	- 목적: 모델을 실제 환경에 적용하고 지속적으로 성능 관리
	- 주요 활동
		- 모델 패키징 및 API 개발
			- 모델 버전 관리
		- 생산 환경 통합
		- 성능 모니터링 및 재학습 계획 수립
			- 데이터 분포 변화 감지
				- 시간이 지남에 따라 데이터의 통계적 특성이나 패턴이 변하는 현상을 모니터링하고 식별


### 2. 대표적인 분류 알고리즘 소개

#### 로지스틱 회귀
가장 기초적이고 널리 쓰이는 이진 분류 알고리즘.
직선 또는 초평면으로 데이터를 구분하며, 확률 기반의 예측값을 제공

##### 작동 원리
- 입력값의 선형 결합 z를 계산
- 시그모이드 함수를 통해 z를 0~1 사이 확률로 변환
- 임계값(기본은 0.5)을 기준으로 클래스 분류

##### 수식 요약
- $z = w_0 + w_1x_1 + ... + w_nx_n$
-  $\hat{y} = \frac{1}{1 + e^{-z}}$

##### 장단점
- 장점
	- 계산 효율성이 높고 학습 속도가 빠름
	- 과적합 위험이 낮고 해석이 용이함
	- 확률값을 직접 제공하여 의사결정에 활용 가능
	- 적은 데이터에서도 준수한 성능
- 단점
	- 복잡한 비선형 관계 포착에 한계가 있음
	- 특성 간 상호작용 모델링이 어려움
	- 이상치에 민감할 수 있음
	- 클래스 불균형 데이터에 민감함

##### Tip
- 특성 스케일링을 사용하는 것이 좋음
- 데이터가 적거나 고차원 희소 데이터일 때 우수한 성능
- 규제 강도를 조절하는 c 파라미터 튜닝 중요