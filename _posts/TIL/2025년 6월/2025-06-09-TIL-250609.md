---
title: "[TIL] 2025. 6. 9."
date: 2025-06-09
categories:
  - TIL
tags:
  - TIL
  - 내일배움캠프
toc: true
toc_sticky: true
---
## 최종 프로젝트

### 아고다와 에어비엔비 숙박요금 웹 크롤링

- 1인 숙박 요금을 정확히 계산하는 것은 까다롭기 때문에 객실 1개를 기준으로 잡음
- 도시는 라이브러리를 이용하지 않고 직접 만든 world_cities.csv 파일을 이용하여 검색
- 되도록이면 많은 곳의 숙박요금 수집(6시간 소요 예정이나 더 걸릴 수 있음)
- 과거 요금을 검색하기 어려워 내년 6월까지 약 1년 간의 날짜 중 랜덤으로 골라 요금 수집
- 그런데 날짜를 굳이 랜덤으로 추출할 필요가 있나 의심이 되긴 함
- 요금은 평일인지 주말인지, 성수기인지 비수기인지에 따라 요금에 차이가 생기므로 골라야할 필요가 있음
- 에어비엔비도 같은 코드에서 사이트 주소만 바꿔서 크롤링 하는 중

```python
import pandas as pd
import random, re, time
from datetime import datetime, timedelta
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.chrome.options import Options

# 날짜 랜덤으로 추출
def generate_random_dates(n=12):
    dates = []
    for _ in range(n):
        days_ahead = random.randint(7, 365)
        checkin = datetime.today() + timedelta(days=days_ahead)
        checkout = checkin + timedelta(days=1)
        dates.append((
            checkin.strftime("%Y-%m-%d"),
            checkout.strftime("%Y-%m-%d")
        ))
    return dates

  

# 요금 추출
def extract_price(text):
    numbers = re.findall(r"\d+", text.replace(",", ""))
    return int("".join(numbers)) if numbers else None

# 도시별 숙박요금 수집
def crawl_prices_for_city(city_name, date_pairs):
    prices = []
    print(f"도시: {city_name}")
    for checkin, checkout in date_pairs:
        options = Options()
        options.add_argument("--headless")
        options.add_argument("--disable-blink-features=AutomationControlled")
        driver = webdriver.Chrome(options=options)
        try:
            # 접속 및 검색
            driver.get("사이트 주소소")
            time.sleep(3)
            search_box = driver.find_element(By.ID, "textInput")
            search_box.clear()
            search_box.send_keys(city_name)
            time.sleep(2)
            search_box.send_keys(Keys.ENTER)
            time.sleep(6)

            # URL에 날짜 추가
            url = driver.current_url
            if "checkIn" not in url:
                url += f"&checkIn={checkin}&checkOut={checkout}"
                driver.get(url)
                time.sleep(5)

            # 무한 스크롤 (최대 20초)
            start = time.time()
            while time.time() - start < 20:
                driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
                time.sleep(2)

            # 요금 수집
            price_elements = driver.find_elements(By.CSS_SELECTOR, "[data-selenium='hotel-price']")
            for elem in price_elements:
                price = extract_price(elem.text)
                if price:
                    prices.append(price)

        except Exception as e:
            print(f"에러 ({city_name}, {checkin}): {e}")
        finally:
            driver.quit()
    return prices


# 도시 목록 불러오기
df = pd.read_csv("world_cities.csv")
city_columns = df.columns[1:]
city_names = []
for col in city_columns:
    city_names += df[col].dropna().tolist()
unique_cities = sorted(set(city_names))


# 크롤링 실행
results = []
date_samples = generate_random_dates(12)

for city in unique_cities:
    prices = crawl_prices_for_city(city, date_samples)
    avg_price = round(sum(prices)/len(prices), 2) if prices else None
    results.append({
        "도시명": city,
        "총 숙소 수": len(prices),
        "평균 숙박요금": avg_price
    })

# 저장

df_out = pd.DataFrame(results)
df_out.to_csv("avg_prices_by_city.csv", index=False, encoding="utf-8-sig")
print("결과 저장: avg_prices_by_city.csv")
```
